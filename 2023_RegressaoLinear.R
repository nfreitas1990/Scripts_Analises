

# An√°lise: REGRESSAO LINEAR SIMPLES 
# Atualizado: Fevereiro 2023
# Autor: NATALIA F SOUZA


# Pacotes -----------------------------------------------------------------
library(ggplot2)
library(tidyverse)
library(plotly)
library(knitr)
library(kableExtra)

# Pacotes utilizados ------------------------------------------------------
pacotes <- c("plotly","tidyverse","ggrepel","fastDummies","knitr","kableExtra",
             "splines","reshape2","PerformanceAnalytics","correlation","see",
             "ggraph","psych","nortest","rgl","car","ggside","tidyquant","olsrr",
             "jtools","ggstance","magick","cowplot","emojifont","beepr","Rcpp",
             "equatiomatic")

options(rgl.debug = TRUE)

if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){
  instalador <- pacotes[!pacotes %in% installed.packages()]
  for(i in 1:length(instalador)) {
    install.packages(instalador, dependencies = T)
    break()}
  sapply(pacotes, require, character = T) 
} else {
  sapply(pacotes, require, character = T) 
}


# Contextualiza√ß√£o --------------------------------------------------------

# Modelos Supervisionados: estima modelos que embora sejam simplifica√ß√µes 
# da realidade, apresentam a melhor aderencia poss√≠vel entre os valores reais
# e previstos.

# Quando modelos tentamos minimizar a distancia entre os valores reais e os
# valores preditos pelo modelo.

# Existem dois problemas em modelagem supervisionada:
# 1. Regress√£o: Y √© um vari√°vel cont√≠nua
# 2. Classifica√ß√£o: Y √© uma vari√°vel categ√≥rica

 
# Formula -----------------------------------------------------------------
# y = Bo + B1X1 +B2X2 + E

# Bo:  Intercepto (coeficiente linear) - ponto em que a reta projetada toca 
#      o eixo y, quando x = 0
# B1: Inclina√ß√£o (Coeficiente angular) - quanto se aumenta em Y ao alterar 1 
#     unidade de X. 

# Objetivo ----------------------------------------------------------------
# Avaliar a relacao de causa e efeito a respeito de duas variaveis 
# quantitativas. Essa relacao serah descrita em uma equacao matematica.
# Ao olhar essa equacao vamos interpreta-la no mundo real.


# Pressuposto -------------------------------------------------------------
# 1. Funcao que descreve a relacao entre as vari√°veis eh uma reta. 
#    Portanto, temos um modelo linear;

# 2. Normalidade dos residuos;

# 3. Homocedasticidade dos residuos - ao longo da variacao dos dados, 
#    os res√≠duos variam de forma homogenea ao longo da regressao 
#    (no comeco, meio e final). 

# Hip√≥teses ---------------------------------------------------------------
# Ho: B1 = 0 - N√£o h√° rela√ß√£o entre a vari√°vel resposta e a explicativa
# Ha: B1 =!0 - H√° rela√ß√£o entre a vari√°vel resposta e a explicativa

# Outcome -----------------------------------------------------------------
# A primeira coisa que devemos fazer para selecionar corretamente os modelos
# √© olhar para a variavel resposta


# Minimos Quadrados -------------------------------------------------------
#> A reta da regress√£o √© criada de modo que a Soma dos quadrados seja 
#> minimizada. Retas que passam longe da nuvem de pontos d√° uma soma
#> dos quadrados sempre maior. 
#> Esse m√©todo seleciona o intercepto e inclina√ß√£o que minimizam o somat√≥rio
#> dos erros ao quadrado. Com a  restri√ß√£o de que o somat√≥rio dos erros tem 
# que ser zero.

# Pressupoe: Soma dos erros = zero
#            Soma dos erros ao quadrado= √© o m√≠nimo


# R¬≤ ----------------------------------------------------------------------
# O R¬≤ representa o quanto da varia√ß√£o de Y √© explicada pelo modelo. O R¬≤ √©
# a correla√ß√£o de Pearson ao quadrado. O r de Pearson foi elevado ao quadrado
# para que a escala n√£o d√™ valores negativos. Pois, a correla√ß√£o entre valores
# preditos e observado nunca pode ser negativo, necessariamente, valores
# maiores de Y tenderao a estar associados a valores maiores preditos pela reta
# Mas em essencia s√£o a mesma coisa r de pearson e R2 sao a mesma coisa  

# O valor de R¬≤ indica o percentual de vari√¢ncia da vari√°vel Y que √© devido ao
# comportamento de varia√ß√£o conjunta da(s) vari√°vel(is) explicativa(s) X.
# Varia de 0 a 1 e, quanto maior o coeficiente, maior o poder
# preditivo do modelo de regress√£o, ou seja, maior o poder de
# explica√ß√£o do comportamento da vari√°vel dependente frente ao
# comportamento da(s) vari√°vel(is) explicativa(s).

# O R¬≤ consiste na formula: 
#             (somat√≥rio dos desvios (obs-esp) ao quadrado) / 
# (somat√≥rio dos desvios (obs-esp) ao quadrado) + (somat√≥rio dos erros ao quadrado)



# R¬≤ Ajustado -------------------------------------------------------------
# Quando houver o intuito de se compararem os resultados das
# estima√ß√µes de dois modelos com quantidades distintas de par√¢metros
# e/ou obtidos a partir de amostras com tamanhos diferentes, faz-se
# necess√°rio o uso do R¬≤ ajustado.

# O R¬≤ ajustado leva em considera√ß√£o a quantidade de variaveis explicativas
# colocadas no modelos, penalizando o modelo pelo excesso de vari√°veis




# Teste F -----------------------------------------------------------------
# Permite analisar se pelo menos um dos betas √© estatisticamente
# significante para a explica√ß√£o do comportamento de Y no modelo. 
# √â respons√°vel pelo valor do p-valor do teste global no modelo.

# H0: ùõΩ1 = ùõΩ2 = ùõΩ3 = ‚ãØ = ùõΩùëò = 0
# H1: pelo menos um ùõΩ ‚â† 0

# Na rejei√ß√£o da hip√≥tese nula, pelo menos um dos b ‚Äôs ser√° estatisticamente
# diferente de zero para explicar o comportamento de Y -> p-valor abaixo do
# n√≠vel cr√≠tico (0,05, usualmente).




# Teste t -----------------------------------------------------------------
# Permite analisar se cada um dos par√¢metros (betas), individualmente, √©
# estatisticamente diferente de zero (no caso de regress√£o simples, apresenta a
# mesma signific√¢ncia da estat√≠stica F).

# H0: ùõΩ = 0 
# H1: ùõΩ ‚â† 0

# Distribui√ß√£o F ----------------------------------------------------------
# Graus de liberdade do modelo (k): corresponde a quantidade de vari√°vel X
# Grasu de liberdade do erro: (n-k)-1

# F = (SomaQuadrados Regress√£o/"k"grausLiberdade modelo)/ (SomaQuadrados erros/ n-k-1)




# Problema de significancia do Intercepto -------------------------------------
# As vezes o valor do intercepto pode nao ser significativo. quando isso acontece
# √© uma indicacao de amostra pequena. Apesar de nao ser indicado, nao 
# podemos fazer nada.



# Dummies: Vari√°veis Qualitativas ----------------------------------------------
# Para trabalhar com vari√°veis qualitativas, estas devem ser transformadas para 
# vari√°veis dummies (one hot incode). Dummies S√£o vari√°veis categ√≥ricas que 
# representam um atributo por meio de combina√ß√£o bin√°ria (0 para a aus√™ncia 
# ou 1 para presen√ßa).


# Transforma√ß√£o  de BoxCox -----------------------------------------------------
# Quando os res√≠duos n√£o possuem distribui√ß√£o normal. Podemos transformar a 
# vari√°vel Y na tentativa de normalizar a distribui√ß√£o e atender a esse pressuposto
# Determina Qual o valor de lambda (lambda varia entre ‚Äì‚àû e +‚àû) que maximiza a 
# ader√™ncia da distribui√ß√£o da nova vari√°vel Y* √† normalidade

# S√≥ podemos aplicar boxcox para vari√°vel positiva que n√£o contem zero. Ent√£o
# caso tenha zero temos que somar 1 ou 0.001

# Script Complementar: 2023_Transforma√ß√£o_Normalizacao

# Ent√£o, podemos usar o lambda que a an√°lise fornecer na formula para transformar
# o Y. 
# 1- DESCOBRIR O MELHOR LAMBDA
# lambda <- car::powerTransform(variavel Y)
# 2- CRIAR VARI√ÅVEL TRANSFORMADA NO DATASET
# Ytransformado = (Y^Œª - 1)/ Œª

# ou simplesmente usar uma transforma√ß√£o j√° conhecida para transformar o Y, 
# usando como base o valor de lambda obtido

# Tabela de Resultado
# lambda    Transforma√ß√£o
# -2        y^-2
# -1        y^-1    - inversa
# -0.5      y^-0.5  - raiz quadratica inversa
# 0         log(y)  - logaritma ln(x) - logaritmo natural
# 0.5       sqrt(y) - raiz quadrada
# 1         y       - linear
# 2         y^2     - quadratica
# 3         y^3     - cubica



#     #     #     #       #      #      #     #       #       #
# Exemplo: Analise lm ----------------------------------------------------------
dados <- read.table("raw_datas_exemplos/especies.txt",header = T)
head(dados)

# Modelo nulo
mod0 <- lm(Species ~ 1, data= dados)
# Modelo 1
mod1 <- lm(Species ~ Biomass, data= dados)
# Modelo 2
mod2 <- lm(Species ~ Biomass+pH, data= dados)
# Modelo 3
mod3 <- lm(Species ~ Biomass+pH+Biomass:pH, data= dados)

# Compara√ß√£o de Modelos usando ANOVA
# Se os modelos s√£o diferentes (p<0.05), escolher o modelo mais complexo
# Se os modelos n√£o s√£o diferentes (p>0.05), manter o modelo mais simples
anova(mod0,mod1)
anova(mod1,mod2)
anova(mod2,mod3)

# Selecionar o modelo 2
lm <- lm(Species ~ Biomass + pH, data= dados)
summary(lm)
plot(lm)  
summary(mod2)


#     #     #     #       #      #      #     #       #       #
# Exploratorio ------------------------------------------------------------
dplyr::glimpse(Boston) 


#x ------------------------------------------------------------------
# An√°lise de Regress√£o SIMPLES --------------------------------------------

  # dados Boston de Exemplo
  library(MASS) 
  # Dados
  data(Boston)
  
  # Analise
  mod_simples <- lm (medv ~ rm, Boston) 



# Resumo dos Resultados ---------------------------------------------------
  summary(mod_simples)
  
# Call: Mostra a f√≥rmula que rodou a an√°lise. Muito √∫til para olhar os resultados
#       depois da an√°lise pronta.

# Residuals: Para olhar a distribui√ß√£o dos res√≠duos. Conseguimos ver se os 
#            pressupostos da distribui√ß√£o foram cumpridos.
#            A m√©dia dos res√≠duos deve estar pr√≥xima a ZERO e os valores de 
#            minimo e m√°ximo devem estar pr√≥ximos em valor absoluto.
  
# Coefficients: 
  # Intercept: O valor do intercepto tem import√¢ncia no contexto matem√°tico, 
  # mas pouca utilidade para a interpreta√ß√£o do problema. Significa que quando
  # a vari√°vel explicativa for igual a ZERO, esperamos que a vari√°vel resposta 
  # seja igual ao intercepto.
  # Slope: O aumento em 1 unidade de X (var. explicativa) provoca aumento/diminui√ß√£o
  # do Y em "valor do slope" unidades de Y.

# Residual standard error: Varia√ß√£o residual. Expressa a varia√ß√£o das observa√ß√µes 
#                          em torno da linha de regress√£o.  

# R-square: Indica a quantidade de varia√ß√£o em Y (vari√°vel resposta) que √© 
#           explicada pela vari√°vel explicativa (X). Ao multiplicar por 100,
#           temos o percentual. Ao tirar a raiz quadrada desse valor, temos
#           o coeficiente de correla√ß√£o de Pearson.

# Adjusted R-square: O R-square tem um problema que ele sempre aumenta de valor
# conforme aumentamos o numero de preditores. Isso porque aumenta a quantidade
# de varia√ß√£o que √© explicada. O R-ajustado tenta contornar esse problema, 
# compensanso o n√∫mero de par√¢metros usados. Portanto, pode ser usado para 
# comparar modelos. Ao adicionar mais uma vari√°vel podemos ver o quanto ela 
# interfere no R-ajustado, se ela diminuir muito o R-ajustado em compara√ß√£o
# com o R-square, ent√£o n√£o vale a pena colocar essa nova vari√°vel.
  
# F-statistic: √© mais importante na regress√£o m√∫ltipla. Quanto maior 
# o valor de F, maior a inclina√ß√£o da reta e menor √© p-valor.

# p-value: Probabilidade de obter a raz√£o F observada se a hip√≥tese nula for
# verdadeira. Se a probabilidade de obter a raz√£o observada for pequena (<0.05)
# a probabilidade de obter o nosso resultado ao acaso √© improv√°vel. Ent√£o,
# rejeitamos a hip√≥tese nula (B1=0) e conclu√≠mos que o modelo de regress√£o 
# explica mais varia√ß√£o do que o esperado apenas ao acaso.   
  

# ALTERNATIVA AO SUMMARY
  jtools::summ(mod_simples, confint = T, digits = 4, ci.width = .95)
  jtools::export_summs(mod_simples, scale = F, digits = 4)
  

# Outras formas de visualizar os resultados --------------------------------

coef(mod_simples)                             # coeficientes
confint(mod_simples)                          # intervalo confianca
predict(mod_simples)                          # valores preditos
predict(mod_simples, interval = "confidence", level = 0.95) # valores preditos c/ intervalos
res <-  broom::augment(mod_simples)           # res√≠duos|cook distance|erro padr√£o|intervalos de confian√ßa

# ou 
broom::augment(mod_simples)

# ou 
gtsummary::tbl_regression(mod_simples)

# Grafico Regress√£o ---------------------------------------------------------

# Grafico da regressao 
ggplot(Boston, mapping = aes(y = medv, x=rm))+
  geom_point()+
  geom_line(res, mapping = aes(y =.fitted , x=rm))+
  theme_classic()

# ou
plot(medv ~ rm, Boston)
abline(mod_simples)

# ou
ggplot(data = Boston, aes(x = rm, y = medv)) +
  geom_point() +
  stat_smooth(method = "lm", se = FALSE)+
  theme_classic()

# ou (interativo)
ggplotly(
  ggplot(Boston, aes(x = rm, y = medv)) +
    geom_point(color = "#39568CFF", size = 2.5) +
    geom_smooth(aes(color = "Fitted Values"),
                method = "lm", formula = y ~ x, se = F, size = 2) +
    labs(x = "Dist√¢ncia",
         y = "Tempo",
         title = paste("R¬≤:",
                       round(((cor(Boston$rm, Boston$medv))^2),4))) +
    scale_color_manual("Legenda:",
                       values = "grey50") +
    theme_classic()
)

# com intervalo de confianca de 95%
ggplotly(
  ggplot(Boston, aes(x = rm, y = medv)) +
    geom_point(color = "#39568CFF") +
    geom_smooth(aes(color = "Fitted Values"),
                method = "lm", formula = y ~ x,
                level = 0.95) +
    labs(x = "Dist√¢ncia",
         y = "Tempo") +
    scale_color_manual("Legenda:",
                       values = "grey50") +
    theme_bw()
)


# Graficos Diagn√≥stico ----------------------------------------------------

plot(lm (medv ~ rm, Boston) )

# Residual vs Fitted: Queremos nesse gr√°fico n√£o observar padr√µes dos pontos 
# no grafico. Quando mais disperso os valores dos res√≠duos estiverem em torno 
# da linha do Zero, melhor. ESSE GR√ÅFICO TESTA A HOMOCEDASTICIDADE DO RES√çDUO.

# Normal Q-Q: Queremos que os pontos estejam praticamente em cima da linha 
# pontilhada prevista. Se os pontos saem da reta prevista, significa que os 
# res√≠duos da regress√£o n√£o s√£o normais. ESSE GR√ÅFICO TESTA A NORMALIDADE DOS 
# RES√çDUOS. INDICIO DE TERMO UMA RELA√á√ÉO LINEAR ENTRE AS VARI√ÅVEIS.

# Scale-Location:

# Residuals vs Leverage: Distancia de cook mostra quais s√£o os pontos influentes.
# Pontos com potencial para alavancar a reta da regress√£o. Os pontos que 
# aparecem com as linhas ao lado, s√£o outliers. As linhas pontilhadas(0.5, 1) 
# mostram a gravidade de influencia desses pontos. A distancia de cook mede o 
# efeito de excluir uma observa√ß√£o. Ajusta uma reta a cada vez que roda, deixando 
# um ponto de fora.
# Valores podem ser acessados:
cooks.distance(mod_simples)

# PRESSUPOSTO: Normalidade dos res√≠duos
  # Exemplo
    library(statsr)
    library(ggplot2)
    data("mlb11")
    m1 <- lm(runs ~ at_bats, data = mlb11)
    

    
    # 1. Grafico qqplot
    plot(m1)
    #ou
    ggplot(data = m1, aes(sample = .resid)) +
          stat_qq()

  # 2. Historama: com a distribui√ß√£o dos res√≠duos
    ggplot(data = m1, aes(x = .resid)) +
        geom_histogram(binwidth = 25) +
        xlab("Residuals")

# PRESSUPOSTO: Homocedasticidade dos res√≠duos
  
  ggplot(data = m1, aes(x = .fitted, y = .resid)) +
      geom_point() +
      geom_hline(yintercept = 0, linetype = "dashed") +
      xlab("Fitted values") +
      ylab("Residuals")

  
# Pontos de Influencia ----------------------------------------------------
# Outliers podem ser pontos de influencia. Dependendo de onde ele est√° localizado
# pode servir de ponto de alavanca e interferir na inclina√ß√£o da reta. Se ele
# est√° nas extremidades da distribui√ß√£o dos pontos, pode ser alavanca.




# Predi√ß√£o ----------------------------------------------------------------

# Modela
  model2 <- lm(runs ~ at_bats, data = mlb11)
  summary(model2)

# Valor Predito de runs quando at_bats = 5579
  predict_runsvalue <- -2789.2429 + (0.6305 * 5579)
  predict_runsvalue

# Valor Observado: Para 5579 foi observado o valor de 713 runs
observed_runsvalue <- mlb11 %>% 
                          select(runs, at_bats) %>% 
                          filter(at_bats == 5579)
# Res√≠duos
residualvalue <- observed_runsvalue$runs - predict_runsvalue 
residualvalue
  
# Grafico da regress√£o
ggplot(data = mlb11, aes(x = at_bats, y = runs)) +
  geom_point() +
  stat_smooth(method = "lm", se = FALSE)


# Compara√ß√£o de Modelos ---------------------------------------------------
mod_1 <- lm (medv ~ rm, Boston) 
mod_2 <- lm (medv ~ ., Boston) #todas as variaveis
# funcao comparacao
jtools::export_summs(mod_1,mod_2, scale = F, digits = 4)



#x ------------------------------------------------------------------
# Analise Regress√£o Multipla ----------------------------------------------

# Dados Boston de Exemplo
library(MASS) 

# Analise


# METODO 1 - interpretacao direta. Uma unidade de X afeta Y de acordo com  a 
# estimativa de beta. Neste metodo, nao ocorreu padronizacao das variaveis. 
# Entao nao podemos inferir qual seria a variavel mais importante para o modelo
# porque a escala das variaveis nao e a mesma. Este caso nao-padronizado eh
# melhor para predicao e para ver o quanto que a alteracao de uma unidade varx
# altera em var.y, mas nao para comparar o efeito de cada variavel
mod_multiplo <- lm (medv ~ rm + crim, Boston) 
mod_multiplo <- lm (medv~ . -rm, Boston) # excluindo rm da analise


# METODO 2 - Neste caso, padronizamos todas as variaveis (inclusive a variavel
# resposta) para determinar qual e a magnitude que a variavel preditora modifica
# a variavel resposta. Para remover o efeito das diferencas de escala entre as 
# variaveis respostas padronizamos  (observacao-media/desvio padrao). Assim, 
# removemos o efeito da escala e podemos de maneira correta observar o efeito 
# da preditora na var. resposta em termos de desvio padrao. Temos o efeito na 
# mesma escala para todas as variaveis, o que permite fazer uma inferencia.
# Regressao padronizando todas as variaveis
library(arm)
mod_multiplo = standardize(lm(medv~ . , Boston),
            standardize.y = TRUE)
summary(mod_multiplo)

# ou 
broom::augment(mod_multiplo)

# ou 
gtsummary::tbl_regression(mod_multiplo)


# Graficos Diagn√≥stico
plot(mod_multiplo)


# Colinearidade -----------------------------------------------------------
# A colinearidade ocorre quando existe uma alta correlacao entre duas 
# variaveis preditoras que, normalmente, representam o mesmo fenomeno 
# ou muitos similares.



#------ Identificar a colinearidade

# - correlacao entre as variaveis preditoras
cor.test()


# - graficos de scatterplot entre as variaveis



# - Gr√°fico de correla√ß√£o
#A fun√ß√£o 'correlation' do pacote 'correlation' faz com que seja estruturado um
#diagrama interessante que mostra a inter-rela√ß√£o entre as vari√°veis e a
#magnitude das correla√ß√µes entre elas
#Requer instala√ß√£o e carregamento dos pacotes 'see' e 'ggraph' para a plotagem
library(see)
library(ggraph)
library(correlation)
library(MASS)
data("Boston")
Boston %>%
  correlation(method = "pearson") %>%
  plot()

#A fun√ß√£o 'chart.Correlation' do pacote 'PerformanceAnalytics' apresenta as
#distribui√ß√µes das vari√°veis, scatters, valores das correla√ß√µes e suas
#respectivas signific√¢ncias
PerformanceAnalytics::chart.Correlation((Boston[2:4]), histogram = TRUE)






# Interacao como deve ser inserida
## uma forma de representar a interacao - faz todas as interacoes entre 
## as variaveis utilizadas no modelo
modelo2 <- lm(log_riqueza ~ log_area * precipitacao, data = ilhas)

## outra forma de representar a interacao
modelo2 <- lm(log_riqueza ~ log_area + precipitacao + log_area : precipitacao,
              data = ilhas)




# Reportar sempre R-square ajustado (leva em consideracao o numero de variaveis
# preditoras no modelo para estimar o coeficiente de determinacao);



# OBS: COLINEARIDADE
# Quando acontece isso temos um problema. Temos estimativas equivocadas.
# Nesses casos a regress√£o pode dar significativa, enquanto as vari√°veis em si,
# n√£o d√£o significativas para as suas inclina√ß√µes. Neste caso temos q usar apenas
# uma das vari√°veis.




# Tidymodels --------------------------------------------------------------
library(tidymodels)
library(MASS) 
Boston

receita <- 
  linear_reg() |> 
  set_engine("glm") |> 
  set_mode("regression") 

mod1 <- receita |> 
  fit(medv ~ rm, data = Boston)  
summary(mod1)
  


#x ------------------------------------------------------------------
# Exemplo1 -------------------------------------------------------------

# Linear Simples ----------------------------------------------------------


# Pacotes -----------------------------------------------------------------
#Pacotes utilizados
pacotes <- c("plotly","tidyverse","ggrepel","fastDummies","knitr","kableExtra",
             "splines","reshape2","PerformanceAnalytics","correlation","see",
             "ggraph","psych","nortest","rgl","car","ggside","tidyquant","olsrr",
             "jtools","ggstance","magick","cowplot","emojifont","beepr","Rcpp",
             "equatiomatic")




options(rgl.debug = TRUE)

if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){
  instalador <- pacotes[!pacotes %in% installed.packages()]
  for(i in 1:length(instalador)) {
    install.packages(instalador, dependencies = T)
    break()}
  sapply(pacotes, require, character = T) 
} else {
  sapply(pacotes, require, character = T) 
}

# Dados -------------------------------------------------------------------
#Listar os arquivos do nosso project
list.files()

#Carregando a base de dados
load(file = "raw_datas_exemplos/tempodist.RData")


# Exploratorio ------------------------------------------------------------
tempodist %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped",
                full_width = F,
                font_size = 22)

#Visualizando as observa√ß√µes e as especifica√ß√µes referentes √†s vari√°veis do dataset
glimpse(tempodist) 

#Estat√≠sticas univariadas
summary(tempodist)


# Grafico -----------------------------------------------------------------
ggplotly(
  ggplot(tempodist, aes(x = distancia, y = tempo)) +
    geom_point(color = "#39568CFF", size = 2.5) +
    geom_smooth(aes(color = "Fitted Values"),
                method = "lm", formula = y ~ x, se = F, size = 2) +
    labs(x = "Dist√¢ncia",
         y = "Tempo",
         title = paste("R¬≤:",
                       round(((cor(tempodist$tempo, tempodist$distancia))^2),4))) +
    scale_color_manual("Legenda:",
                       values = "grey50") +
    theme_classic()
)

# Analise -----------------------------------------------------------------
#Estimando o modelo
modelo_tempodist <- lm(formula = tempo ~ distancia,
                       data = tempodist)




# Resultado ---------------------------------------------------------------

#Op√ß√£o1
#Observando os par√¢metros do modelo_tempodist
summary(modelo_tempodist)

#Op√ß√£o2
# Outras maneiras de apresentar os outputs do modelo
# fun√ß√£o 'summ' do pacote 'jtools'
summ(modelo_tempodist, confint = T, digits = 4, ci.width = .95)
export_summs(modelo_tempodist, scale = F, digits = 4)

#Visualiza√ß√£o do modelo no ambiente Viewer
#fun√ß√£o 'extract_eq' do pacote 'equatiomatic'
extract_eq(modelo_tempodist, use_coefs = T) %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped",
                full_width = F,
                font_size = 28)


# Salvar Fitted values ----------------------------------------------------
# Salvando fitted values (vari√°vel yhat) e residuals (vari√°vel erro) no dataset
tempodist$yhat <- modelo_tempodist$fitted.values
tempodist$erro <- modelo_tempodist$residuals

#Visualizando a base de dados com as vari√°veis yhat e erro
tempodist %>%
  select(tempo, distancia, yhat, erro) %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped", 
                full_width = F, 
                font_size = 22)


# Grafico com R¬≤ ----------------------------------------------------------
# Gr√°fico did√°tico para visualizar o conceito de R¬≤
ggplotly(
  ggplot(tempodist, aes(x = distancia, y = tempo)) +
    geom_point(color = "#39568CFF", size = 2.5) +
    geom_smooth(aes(color = "Fitted Values"),
                method = "lm", formula = y ~ x, se = F, size = 2) +
    geom_hline(yintercept = 30, color = "grey50", size = .5) +
    geom_segment(aes(color = "Ychap√©u - Ym√©dio", x = distancia, xend = distancia,
                     y = yhat, yend = mean(tempo)), size = 0.7, linetype = 2) +
    geom_segment(aes(color = "Erro = Y - Ychap√©u", x = distancia, xend = distancia,
                     y = tempo, yend = yhat), size = 0.7, linetype = 3) +
    labs(x = "Dist√¢ncia",
         y = "Tempo") +
    scale_color_manual("Legenda:",
                       values = c("#55C667FF", "grey50", "#440154FF")) +
    theme_classic()
)

# Calculo Manual do R¬≤ -----------------------------------------------------------
R2 <- (sum((tempodist$yhat - mean(tempodist$tempo))^2))/
  ((sum((tempodist$yhat - mean(tempodist$tempo))^2)) + (sum((tempodist$erro)^2)))

round(R2, digits = 4)

# Coeficiente de ajuste (R¬≤) √© a correla√ß√£o ao quadrado
cor(tempodist[1:2])

# Modelo auxiliar para mostrar R¬≤ igual a 100% (para fins did√°ticos)
# Note que aqui o yhat √© a vari√°vel dependente
modelo_auxiliar <- lm(formula = yhat ~ distancia,
                      data = tempodist)
summary(modelo_auxiliar)

#Gr√°fico mostrando o perfect fit
my_plot <-
  ggplot(tempodist, aes(x = distancia, y = yhat)) +
  geom_point(color = "#39568CFF", size = 5) +
  geom_smooth(aes(color = "Fitted Values"),
              method = "lm", formula = y ~ x, se = F, size = 2) +
  labs(x = "Dist√¢ncia",
       y = "Tempo") +
  scale_color_manual("Legenda:",
                     values = "grey50") +
  theme_cowplot()
my_plot

#Com figuras JPEG e PNG
ggdraw() + #fun√ß√µes 'ggdraw', 'draw_image' e 'draw_plot' do pacote 'cowplot'
  draw_image("https://cdn.pixabay.com/photo/2021/12/14/16/32/harry-potter-6870854_960_720.png",
             x = 0.075, y = -0.15, scale = .44) +
  draw_image("https://img.freepik.com/fotos-premium/agulha-de-trico-isolada_93675-25968.jpg?w=1380",
             x = -0.235, y = 0.25, scale = .37) +
  draw_plot(my_plot)


# Grafico com intervalo confianca ----------------------------------------
##Voltando ao nosso modelo original:
#Plotando o Intervalo de Confian√ßa de 95%
ggplotly(
  ggplot(tempodist, aes(x = distancia, y = tempo)) +
    geom_point(color = "#39568CFF") +
    geom_smooth(aes(color = "Fitted Values"),
                method = "lm", formula = y ~ x,
                level = 0.95) +
    labs(x = "Dist√¢ncia",
         y = "Tempo") +
    scale_color_manual("Legenda:",
                       values = "grey50") +
    theme_bw()
)


#Calculando os intervalos de confian√ßa

confint(modelo_tempodist, level = 0.90) # siginific√¢ncia 10%
confint(modelo_tempodist, level = 0.95) # siginific√¢ncia 5%
confint(modelo_tempodist, level = 0.99) # siginific√¢ncia 1%
confint(modelo_tempodist, level = 0.99999) # siginific√¢ncia 0,001%

#Fazendo predi√ß√µes em modelos OLS - e.g.: qual seria o tempo gasto, em m√©dia, para
#percorrer a dist√¢ncia de 25km?
predict(object = modelo_tempodist,
        data.frame(distancia = 25))

#Caso se queira obter as predi√ß√µes com os IC
predict(object = modelo_tempodist,
        data.frame(distancia = 25),
        interval = "confidence", level = 0.95)


# x ------------------------------------------------------------------
# Exemplo 2 ---------------------------------------------------------------
# Linear Multipla ----------------------------------------------------------------


# dados
load('scripts/paises.RData')


#Estat√≠sticas univariadas
summary(paises)

#Gr√°fico 3D com scatter
scatter3d(cpi ~ idade + horas,
          data = paises,
          surface = F,
          point.col = "#440154FF",
          axis.col = rep(x = "black",
                         times = 3))
library(car)
library(rgl)

#Estimando a Regress√£o M√∫ltipla
modelo_paises <- lm(formula = cpi ~ . - pais,
                    data = paises)

#Par√¢metros do modelo
summary(modelo_paises)
confint(modelo_paises, level = 0.95) # siginific√¢ncia de 5%

# obs: se o intervalo de confian√ßa n√£o engloba o ZERO, temos um
# valor significativo para os par√¢metros betas

#Outro modo de apresentar os outputs do modelo - fun√ß√£o 'summ' do pacote 'jtools'
summ(modelo_paises, confint = T, digits = 3, ci.width = .95)
jtools::export_summs(modelo_paises, scale = F, digits = 5)

#Salvando os fitted values na base de dados
paises$cpifit <- modelo_paises$fitted.values

#Gr√°fico 3D com scatter e fitted values
scatter3d(cpi ~ idade + horas,
          data = paises,
          surface = T, fit = "linear",
          point.col = "#440154FF",
          axis.col = rep(x = "black",
                         times = 3))


# x ----------------------------------------------------------------
# Exemplo 3 ---------------------------------------------------------------
# Var.Qualitativa ---------------------------------------------------------

# Com vari√°vel qualitativa precisamos transformar a vari√°vel categorica 
# em vari√°veis dummies. Nao podemos simplesmente usar como categorias

#dados
load(file = "scripts/corrupcao.RData")
#Visualiza√ß√£o das observa√ß√µes e das especifica√ß√µes referentes
#√†s vari√°veis da base de dados
glimpse(corrupcao) 

#Observando os r√≥tulos da vari√°vel regiao
levels(glimpse(corrupcao$regiao)) 

#Tabela de frequ√™ncias da vari√°vel regiao
table(corrupcao$regiao) 


#Estat√≠sticas univariadas
summary(corrupcao)

#Explora√ß√£o visual do Corruption Perception Index para cada um dos pa√≠ses
corrupcao %>%
  group_by(regiao) %>%
  mutate(rotulo = paste(pais, cpi)) %>%
  ggplot(aes(x = as.numeric(regiao), y = cpi, label = rotulo)) +
  geom_point(aes(x = regiao, y = cpi), color = "#FDE725FF", alpha = 0.5, size = 5) +
  scale_color_manual("Legenda:",
                     values = "#440154FF") +
  labs(x = "Regi√£o",
       y = "Corruption Perception Index") +
  geom_text_repel() +
  theme_bw()

#Explora√ß√£o visual do Corruption Perception Index para cada um dos pa√≠ses, com
#valores m√©dios por regi√£o
corrupcao %>%
  group_by(regiao) %>%
  mutate(cpi_medio = mean(cpi, na.rm = TRUE)) %>%
  mutate(rotulo = paste(pais, cpi)) %>%
  ggplot(aes(x = as.numeric(regiao), y = cpi, label = rotulo)) +
  geom_point(aes(x = regiao, y = cpi), color = "#FDE725FF", alpha = 0.5, size = 5) +
  geom_line(aes(x = regiao, y = cpi_medio, 
                group = 1, color = "CPI M√©dio"), linewidth = 1.5) +
  scale_color_manual("Legenda:",
                     values = "#440154FF") +
  labs(x = "Regi√£o",
       y = "Corruption Perception Index") +
  geom_text_repel() +
  theme_bw() +
  theme(legend.position = "bottom")

#Estimando um modelo ERRADO, com o problema da pondera√ß√£o arbitr√°ria
modelo_corrupcao <- lm(formula = cpi ~ as.numeric(regiao), 
                       data = corrupcao)

#Observando os par√¢metros do modelo_corrupcao
summary(modelo_corrupcao)

#Calculando os intervalos de confian√ßa
confint(modelo_corrupcao, level = 0.95) # siginific√¢ncia 5%

#Plotando os fitted values do modelo_corrupcao considerando, PROPOSITALMENTE, a
#pondera√ß√£o arbitr√°ria, isto √©, assumindo que a Am√©rica do Sul vale 1; que a 
#Oceania vale 2; a Europa, 3; EUA e Canad√°, 4; e √Åsia, 5.
corrupcao %>%
  mutate(rotulo = paste(pais, cpi)) %>%
  ggplot(aes(x = as.numeric(regiao), y = cpi, label = rotulo)) +
  geom_point(color = "#FDE725FF", alpha = 0.5, size = 4) +
  stat_smooth(aes(color = "Fitted Values"),
              method = "lm", 
              formula = y ~ x,
              se = T) +
  labs(x = "Regi√£o",
       y = "Corruption Perception Index") +
  scale_x_discrete(labels = c("1" = "Am√©rica do Sul", 
                              "2" = "Oceania", 
                              "3" = "Europa", 
                              "4" = "EUA e Canad√°", 
                              "5" = "√Åsia")) +
  scale_color_manual("Legenda:",
                     values = "#440154FF") +
  geom_text_repel() +
  theme_bw() +
  theme(legend.position = "bottom")


# Dummy -------------------------------------------------------------------
#Dummizando a vari√°vel regiao. O c√≥digo abaixo, automaticamente, far√°: a) o
#estabelecimento de dummies que representar√£o cada uma das regi√µes da base de 
#dados; b)remover√° a vari√°vel dummizada original; c) estabelecer√° como categoria 
#de refer√™ncia a dummy mais frequente.
library(fastDummies)
corrupcao_dummies <- dummy_columns(.data = corrupcao,
                                   select_columns = "regiao",
                                   remove_selected_columns = T,
                                   remove_most_frequent_dummy = T) #categoria de referencia sera a mais frequente

#Visualizando a base de dados dummizada
corrupcao_dummies %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped", 
                full_width = F, 
                font_size = 16)

# 

# Analise -----------------------------------------------------------------
#Modelagem com todas as vari√°veis
modelo_corrupcao_dummies <- lm(cpi ~ . - pais, corrupcao_dummies)

#OBSERVA√á√ïES
# note que se fizermos com a formula comum, o R automaticamente cria var.dummies 
# s√≥ que a categoria de referencia muda para ordem alfabetica 
modelo_corrupcao <- lm(cpi ~ . - pais, corrupcao)
summary(modelo_corrupcao)

#Par√¢metros do modelo_corrupcao_dummies
summary(modelo_corrupcao_dummies)

#Plotando o modelo_corrupcao_dummies de forma interpolada
library(ggrepel)
my_plot3 <- 
  corrupcao %>%
  mutate(rotulo = paste(pais, cpi)) %>%
  ggplot(aes(x = as.numeric(regiao), y = cpi, label = rotulo)) +
  geom_point(color = "#FDE725FF", alpha = 0.5, size = 4) +
  stat_smooth(aes(color = "Fitted Values"),
              method = "lm", 
              formula = y ~ bs(x, df = 4),
              se = T) +
  labs(x = "Regi√£o",
       y = "Corruption Perception Index") +
  scale_x_discrete(labels = c("1" = "Am√©rica do Sul", 
                              "2" = "Oceania", 
                              "3" = "Europa", 
                              "4" = "EUA e Canad√°", 
                              "5" = "√Åsia")) +
  scale_color_manual("Legenda:",
                     values = "#440154FF") +
  geom_text_repel() +
  theme_bw() +
  theme(legend.position = "bottom")
my_plot3

# salvar
ggsave("my_plot3.png")


# x ----------------------------------------------------------------
# Pressuposto: Normalidade -----------------------------------------------------

# Pacotes utilizados 
pacotes <- c("plotly","tidyverse","ggrepel","fastDummies","knitr","kableExtra",
             "splines","reshape2","PerformanceAnalytics","correlation","see",
             "ggraph","psych","nortest","rgl","car","ggside","tidyquant","olsrr",
             "jtools","ggstance","magick","cowplot","emojifont","beepr","Rcpp",
             "equatiomatic")

options(rgl.debug = TRUE)

if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){
  instalador <- pacotes[!pacotes %in% installed.packages()]
  for(i in 1:length(instalador)) {
    install.packages(instalador, dependencies = T)
    break()}
  sapply(pacotes, require, character = T) 
} else {
  sapply(pacotes, require, character = T) 
}


# Dados 
load(file = "bebes.RData")


# Exploratorio 
#Estat√≠sticas univariadas
summary(bebes)

# Grafico Dispers√£o 
ggplotly(
  bebes %>% 
    ggplot() +
    geom_point(aes(x = idade, y = comprimento),
               color = "grey20", alpha = 0.6, size = 2) +
    labs(x = "Idade em semanas",
         y = "Comprimento em cm") +
    theme_bw()
)

# Grafico Dispers√£o com emoji 
ggplotly(
  bebes %>%
    ggplot(aes(x = idade, y = comprimento, label = emoji("baby_bottle"))) +
    geom_text(family = "EmojiOne", size = 5, color = "black") +
    labs(x = "Idade em semanas",
         y = "Comprimento em cm") +
    theme_bw()
)

# Grafico Dispers√£o com ajustes (fits) linear e n√£o-linear 
# loess: mostra uma forma de regress√£o polinomial
# Comparando os dois modelos, podemos notar que o modelo n√£o linear ser√° melhor avaliado
# ter√° um R-square maior e menor erro do que o modelo linear, pois est√° mais ajustado
# aos pontos
ggplotly(
  bebes %>% 
    ggplot() +
    geom_point(aes(x = idade, y = comprimento),
               color = "grey20", alpha = 0.6, size = 2) +
    geom_smooth(aes(x = idade, y = comprimento),     # esse mostra o modelo linear (lm)
                method = "lm", formula = y ~ x,
                color = "#FDE725FF", se = F) +
    geom_smooth(aes(x = idade, y = comprimento),     # esse mostra o modelo n√£o linear (loess) 
                method = "loess", formula = y ~ x,
                color = "#440154FF", se = F) +
    labs(x = "Idade em semanas",
         y = "Comprimento em cm") +
    theme_bw()
)

#Estima√ß√£o do modelo OLS linear
modelo_linear <- lm(formula = comprimento ~ idade,
                    data = bebes)

summary(modelo_linear)


# Normalidade -------------------------------------------------------------
# Para os modelos lineares precisaremos realizar um teste para testar os 
# erros em rela√ß√£o aos fitted values. Porque se n√£o houver normalidade
# dos erros (res√≠duos) os betas estimados pelo modelo n√°o podem ser usados
# para fins preditivos. Os betas do modelo, os intervalos de confian√ßa n√£o
# √© adequado para predi√ß√£o.

# Se n√£o houver normalidade temos que investigar a forma funcional da rela√ß√£o
# entre as vari√°veis para saber se haver√° outra rela√ß√£o que melhor representa
# a rela√ß√£o.


# Shapiro-Wilk ------------------------------------------------------------
  # Para Amostras pequenas ( n<= 30 obeserva√ß√µes) √© aconselh√°vel fazer o teste
  # Shapiro-Wilk:
  # Ho: Existe normalidade - Diferen√ßa n√£o s√£o estatisticamente significantes
  # Ha: N√£o Existe normalidade - Diferen√ßas s√£o estatisticamente significantes
  # Logo, se p<0.05 (rejeito Ho) -> n√£o existe normalidade
  # Logo, se p>0.05 (n√£o rejeito Ho) -> existe normalidade
  shapiro.test(modelo_linear$residuals)


# Shapiro-Francia ---------------------------------------------------------
# Para Amostras Grandes (n> 30 obeserva√ß√µes) √© aconselh√°vel fazer o teste
# Shapiro-Francia
nortest::sf.test(modelo_linear$residuals) #fun√ß√£o 'sf.test' do pacote 'nortest'


# Histograma dos res√≠duos -------------------------------------------------
bebes %>%
  mutate(residuos = modelo_linear$residuals) %>%
  ggplot(aes(x = residuos)) +
  geom_histogram(aes(y = ..density..), 
                 color = "grey50", 
                 fill = "grey90", 
                 bins = 30,
                 alpha = 0.6) +
  stat_function(fun = dnorm, 
                args = list(mean = mean(modelo_linear$residuals),
                            sd = sd(modelo_linear$residuals)),
                aes(color = "Curva Normal Te√≥rica"),
                size = 2) +
  scale_color_manual("Legenda:",
                     values = "#FDE725FF") +
  labs(x = "Res√≠duos",
       y = "Frequ√™ncia") +
  theme(panel.background = element_rect("white"),
        panel.grid = element_line("grey95"),
        panel.border = element_rect(NA),
        legend.position = "bottom")

# Visualiza√ß√£o do comportamento dos res√≠duos em fun√ß√£o dos fitted values do
# do modelo linear, com destaque para as distribui√ß√µes das vari√°veis
# (pacote 'ggside')
bebes %>%
  ggplot(aes(x = modelo_linear$fitted.values, y = modelo_linear$residuals)) +
  geom_point(color = "#FDE725FF", size = 2.5) +
  geom_smooth(aes(color = "Fitted Values"),
              method = "lm", formula = y ~ x, se = F, size = 2) +
  geom_xsidedensity(aes(y = after_stat(density)),
                    alpha = 0.5,
                    size = 1,
                    position = "stack") +
  geom_ysidedensity(aes(x = after_stat(density)),
                    alpha = 0.5,
                    size = 1,
                    position = "stack") +
  xlab("Fitted Values") +
  ylab("Res√≠duos") +
  scale_color_tq() +
  scale_fill_tq() +
  theme_tq() +
  theme(ggside.panel.scale.x = 0.4,
        ggside.panel.scale.y = 0.4)



# x -----------------------------------------------------------------------
# x -----------------------------------------------------------------------

# Regressao Multipla: Passo-a-Passo ---------------------------------------

# Dados -------------------------------------------------------------------
load(file = "raw_datas_exemplos/empresas.RData")

# Exploratorio ------------------------------------------------------------
summary(empresas)


# 1. Avaliar Correla√ß√µes --------------------------------------------------

# Opcao 1 
#A fun√ß√£o 'correlation' do pacote 'correlation' faz com que seja estruturado um
#diagrama interessante que mostra a inter-rela√ß√£o entre as vari√°veis e a
#magnitude das correla√ß√µes entre elas
#Requer instala√ß√£o e carregamento dos pacotes 'see' e 'ggraph' para a plotagem
empresas %>%
  correlation(method = "pearson") %>%
  plot()

# Opcao 2
#A fun√ß√£o 'chart.Correlation' do pacote 'PerformanceAnalytics' apresenta as
#distribui√ß√µes das vari√°veis, scatters, valores das correla√ß√µes e suas
#respectivas signific√¢ncias
chart.Correlation((empresas[2:6]), histogram = TRUE)

# Opcao 3
#A fun√ß√£o 'pairs.panels' do pacote 'psych' tamb√©m apresenta as distribui√ß√µes
#das vari√°veis, scatters, valores das correla√ß√µes e suas respectivas
#signific√¢ncias
pairs.panels(empresas[2:6],
             smooth = TRUE,
             lm = TRUE,
             scale = FALSE,
             density = TRUE,
             ellipses = FALSE,
             method = "pearson",
             pch = 1,
             cor = TRUE,
             hist.col = "aquamarine",
             breaks = 12,
             stars = TRUE,       # If TRUE, adds significance level with stars
             ci = TRUE, alpha = 0.05)

# Opcao 4
#A fun√ß√£o 'corr_plot' do pacote 'metan' tamb√©m apresenta as distribui√ß√µes
#das vari√°veis, scatters, valores das correla√ß√µes e suas respectivas
#signific√¢ncias
install.packages("metan")
library(metan)
empresas %>%
  corr_plot(retorno, disclosure, endividamento, ativos, liquidez,
            shape.point = 21,
            col.point = "black",
            fill.point = "#FDE725FF",
            size.point = 2,
            alpha.point = 0.6,
            maxsize = 4,
            minsize = 2,
            smooth = TRUE,
            col.smooth = "black",
            col.sign = "#440154FF",
            upper = "corr",
            lower = "scatter",
            diag.type = "density",
            col.diag = "#440154FF",
            pan.spacing = 0,
            lab.position = "bl")


# 2. Modelo Multiplo ---------------------------------------------------------
#Visualizando a base de dados
empresas %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped", 
                full_width = F, 
                font_size = 22)

# Estimando a Regress√£o M√∫ltipla
modelo_empresas <- lm(formula = retorno ~ . - empresa,
                      data = empresas)
# Par√¢metros do modelo
summary(modelo_empresas)

# Endividamento nao foi significativo
modelo_empresas2 <- lm(retorno ~ . -empresa -endividamento, 
                       data = empresas)
#Par√¢metros do modelo
summary(modelo_empresas2)

# agora disclousure perdeu a significancia, vamos retirar tb
modelo_empresas3 <- lm(retorno ~ . -empresa -endividamento -disclosure, 
                       data = empresas)
#Par√¢metros do modelo
summary(modelo_empresas3)

# 3. Stepwise: Selecao de vari√°veis ----------------------------------------------------

# 1. Definir o argumento k. Este argumento serve para selecionar apenas os 
# betas significativos ao n√≠vel de confianca de 95% (0.05)
qchisq(p = 0.05, df = 1, lower.tail = F)
# resultado: [1] 3.841459 (valor que ser√° usado na funcao do step())
# Checando o n√≠vel de significancia (0.05) do valor de K
round(pchisq(3.841459, df = 1, lower.tail = F), 7)

# 2. Stepwise automatico
step_empresas <- step(modelo_empresas, k = 3.841459)
summary(step_empresas)
# Este procedimento no R removeu a vari√°vel 'endividamento'. Note que a vari√°vel
# 'disclosure' tamb√©m acabou sendo exclu√≠da ap√≥s o procedimento Stepwise, nesta
# forma funcional linear!


# 3. Extrair resultado do Modelo ---------------------------------------------
jtools::export_summs(step_empresas, scale = F, digits = 5)

# Comparar modelos
jtools::export_summs(step_empresas, modelo_empresas3, scale = F, digits = 5)

#Par√¢metros reais do modelo com procedimento Stepwise
confint(step_empresas, level = 0.95) # siginific√¢ncia 5%
plot_summs(step_empresas, colors = "#440154FF") #fun√ß√£o 'plot_summs' do pacote 'ggstance'



# 4. Comparar Importancia das vari√°veis -----------------------------------
# Para comparar importancia das vari√°veis temos q padronizar as vari√°veis 
# para ter betas variando na mesma escala.
# Par√¢metros reais
ggstance::plot_summs(step_empresas, colors = "#440154FF")
# Par√¢metros padronizados
ggstance::plot_summs(step_empresas, scale = TRUE, colors = "#440154FF")

# Adicionando a caracteriza√ß√£o da distribi√ß√£o normal no IC de cada par√¢metro beta
plot_summs(step_empresas, scale = TRUE, plot.distributions = TRUE,
           inner_ci_level = .95, colors = "#440154FF")

# Comparando os Intervalos de Confianca dos betas dos modelos sem e com procedimento Stepwise
plot_summs(modelo_empresas, step_empresas, scale = TRUE, plot.distributions = TRUE,
           inner_ci_level = .95, colors = c("#FDE725FF", "#440154FF"))



# 5. Teste de Aderencia: Normalidade --------------------------------------
# Shapiro-Francia: n > 30
nortest::sf.test(step_empresas$residuals) 

# Resultado p<0.05 - n√£o existe normalidade

# Plotando os res√≠duos do modelo step_empresas
empresas %>%
  mutate(residuos = step_empresas$residuals) %>%
  ggplot(aes(x = residuos)) +
  geom_histogram(color = "white", 
                 fill = "#440154FF", 
                 bins = 30,
                 alpha = 0.6) +
  labs(x = "Res√≠duos",
       y = "Frequ√™ncia") + 
  theme_bw()

# Acrescentando uma curva normal te√≥rica para compara√ß√£o entre as distribui√ß√µes
empresas %>%
  mutate(residuos = step_empresas$residuals) %>%
  ggplot(aes(x = residuos)) +
  geom_histogram(aes(y = ..density..), 
                 color = "white", 
                 fill = "#440154FF", 
                 bins = 30,
                 alpha = 0.6) +
  stat_function(fun = dnorm, 
                args = list(mean = mean(step_empresas$residuals),
                            sd = sd(step_empresas$residuals)),
                linewidth = 2, color = "grey30") +
  scale_color_manual(values = "grey50") +
  labs(x = "Res√≠duos",
       y = "Frequ√™ncia") +
  theme_bw()



# 6. Transforma√ß√£o de Box Cox ---------------------------------------------
# Como os res√≠duos do modelo n√£o foram aderentes a normalidade, vamos fazer
# a transforma√ß√£o de box cox na vari√°vel Y para tentar normalizar, e teremos 
# que rodar novamente o modelo stepwise

# 1. Calcular o Lambda de Box-Cox
lambda_BC <- car::powerTransform(empresas$retorno)
lambda_BC


# 2. Inserir o lambda do Box-Cox na base de dados para a estima√ß√£o de um novo 
# modelo
# Nova coluna com o Y (retorno) recalculado pela formula de transforma√ß√£o de 
# box-cox usando o lambda obtido
empresas$bcretorno <- (((empresas$retorno ^ lambda_BC$lambda) - 1) / 
                         lambda_BC$lambda)

# 3. Visualizando a nova vari√°vel na base de dados
empresas %>%
  select(empresa, retorno, bcretorno, everything()) %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped", 
                full_width = F, 
                font_size = 18)

# 7. Ap√≥s Box-Cox:Estimar Novamente o Modelo  -----------------------------
# Estimando um novo modelo m√∫ltiplo com vari√°vel dependente transformada 
# por Box-Cox
modelo_bc <- lm(formula = bcretorno ~ . -empresa -retorno, 
                data = empresas)

# Par√¢metros do modelo
summary(modelo_bc)

# Aplicando o procedimento Stepwise
qchisq(p = 0.05, df = 1, lower.tail = F)
step_modelo_bc <- step(modelo_bc, k = 3.841459)

# Resultado
summary(step_modelo_bc)
# Note que a vari√°vel 'disclosure' acaba voltando ao modelo na forma
# funcional n√£o linear!


# 8. Verificar Normalidade Novamente --------------------------------------
# Verificando a normalidade dos res√≠duos do modelo step_modelo_bc
nortest::sf.test(step_modelo_bc$residuals)

# Plotando os novos res√≠duos do step_modelo_bc
empresas %>%
  mutate(residuos = step_modelo_bc$residuals) %>%
  ggplot(aes(x = residuos)) +
  geom_histogram(aes(y = ..density..),
                 color = "white",
                 fill = "#287D8EFF",
                 bins = 30,
                 alpha = 0.6) +
  stat_function(fun = dnorm, 
                args = list(mean = mean(step_modelo_bc$residuals),
                            sd = sd(step_modelo_bc$residuals)),
                size = 2, color = "grey30") +
  scale_color_manual(values = "grey50") +
  labs(x = "Res√≠duos",
       y = "Frequ√™ncia") +
  theme_bw()

# 9. Compara√ß√£o Modelos: Com e Sem Box-Cox -----------------------------------
# Resumo dos dois modelos obtidos pelo procedimento Stepwise (linear e com Box-Cox)
jtools::export_summs(step_empresas, step_modelo_bc,
                     model.names = c("Modelo Linear","Modelo Box-Cox"),
                     scale = F, digits = 6)

# Par√¢metros reais do modelo com procedimento Stepwise e Box-Cox
confint(step_modelo_bc, level = 0.95) # siginific√¢ncia 5%
ggstance::plot_summs(step_modelo_bc, colors = "#287D8EFF")

# Par√¢metros padronizados
# Neste caso, percebemos que o disclosure tem uma importancia relativa maior
# do que as demais vari√°veis no modelo
plot_summs(step_modelo_bc, scale = TRUE, colors = "#287D8EFF")

# Adicionando caracteriza√ß√£o da distribi√ß√£o normal no IC de cada par√¢metro beta
plot_summs(step_modelo_bc, scale = TRUE, plot.distributions = TRUE,
           inner_ci_level = .95, colors = "#287D8EFF")

# Comparando os ICs do betas dos modelos sem e com Transforma√ß√£o de Box-Cox
plot_summs(step_empresas, step_modelo_bc, scale = T, plot.distributions = TRUE,
           inner_ci_level = .95, colors = c("#440154FF", "#287D8EFF"))



# 7. Predi√ß√£o do Modelo ---------------------------------------------------
# Exemplo: qual √© o valor do retorno, em m√©dia, para 
# disclosure igual a 50, liquidez igual a 14 e ativo igual a 4000
predict(object = step_modelo_bc, 
        data.frame(disclosure = 50, 
                   liquidez = 14, 
                   ativos = 4000),
        interval = "confidence", level = 0.95)
# fit      lwr      upr
# 1 3.702015 3.665555 3.738476

# ATEN√á√ÉO !!!!
# N√£o podemos nos esquecer de fazer o c√°lculo para a obten√ß√£o do fitted
# value de Y (retorno a escala original)
# (((Y * Lambda) + 1 ))^ (1 / lambda))
(((3.702015 * -0.02256414) + 1)) ^ (1 / -0.02256414)
# [1] 47.74258


# Salvando os fitted values dos modelos step_empresas e step_modelo_bc no
# dataset empresas
empresas$yhat_step_empresas <- step_empresas$fitted.values
empresas$yhat_step_modelo_bc <- (((step_modelo_bc$fitted.values*(lambda_BC$lambda))+
                                    1))^(1/(lambda_BC$lambda))

# Visualizando os dois fitted values no dataset
# modelos step_empresas e step_modelo_bc
empresas %>%
  select(empresa, retorno, yhat_step_empresas, yhat_step_modelo_bc) %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped", 
                full_width = F, 
                font_size = 22)

# Ajustes dos modelos: valores previstos (fitted values) X valores reais
# Aten√ß√£o! Aqui n√£o temos X. Temos o valor predito vs valor real. o 
# tra√ßado √© a rela√ß√£o perfeita (quando acertamos todOs Os valores). 
# Aten√ß√£o !! o tracejado n√£o √© o modelo linear!!!O linear √© o verde e o 
# n√£o linear √© o roxo
empresas %>%
  ggplot() +
  geom_smooth(aes(x = retorno, y = yhat_step_empresas, color = "Stepwise"),
              method = "lm", se = F, formula = y ~ splines::bs(x, df = 5), size = 1.5) +
  geom_point(aes(x = retorno, y = yhat_step_empresas),
             color = "#440154FF", alpha = 0.6, size = 2) +
  geom_smooth(aes(x = retorno, y = yhat_step_modelo_bc, color = "Stepwise Box-Cox"),
              method = "lm", se = F, formula = y ~ splines::bs(x, df = 5), size = 1.5) +
  geom_point(aes(x = retorno, y = yhat_step_modelo_bc),
             color = "#287D8EFF", alpha = 0.6, size = 2) +
  geom_smooth(aes(x = retorno, y = retorno), method = "lm", formula = y ~ x,
              color = "grey30", size = 1.05,
              linetype = "longdash") +
  scale_color_manual("Modelos:", 
                     values = c("#287D8EFF", "#440154FF")) +
  labs(x = "Retorno", y = "Fitted Values") +
  theme(panel.background = element_rect("white"),
        panel.grid = element_line("grey95"),
        panel.border = element_rect(NA),
        legend.position = "bottom")


#x------------------------------------------------------------------
#x------------------------------------------------------------------

# Pressuposto: Multicolinearidade -----------------------------------------
# A colinearidade ocorre quando existe uma alta correlacao entre duas 
# variaveis preditoras que, normalmente, representam o mesmo fenomeno 
# ou muitos similares.A colinearidade ocorre quando duas vari√°veis carregam
# a mesma informa√ß√£o. A multicolinearidade pode ser respons√°vel pela 
# exclus√£o de vari√°veis do modelo. Isso n√£o significa que a vari√°vel 
# exclu√≠da n√£o explica a varia√ß√£o nos dados, mas que explica a mesma 
# por√ß√£o da vari√°vel que j√° foi explicada por outra vari√°vel na qual 
# ela √© correlacionada.

# Consequencias -----------------------------------------------------------
# - possibilidade de interpreta√ß√µes erradas pela eventual distor√ß√£o 
#   dos sinais dos par√¢metros
# - erros nas predi√ß√µes




# Pacotes
library(dplyr)
library(correlation)

# Dados
load("raw_datas_exemplos/salarios.RData")

# Estat√≠sticas univariadas
summary(salarios)
glimpse(salarios)

salarios |> 
  kableExtra::kable() |> 
  kableExtra::kable_styling(bootstrap_options = "striped",
                            full_width = F, font_size = 22)

## Exemplo 1
## CORRELA√á√ÉO PERFEITA:
# Quando temos uma correla√ß√£o perfeita (ou quase perfeita)
# n√£o conseguiremos estimar dois betas, s√≥ conseguiremos 
# estimar 1 beta, pq de uma das vari√°veis o beta vir√° vazio

# Opcao1
cor(salarios$rh1, salarios$econometria1)
# Opcao2
salarios|> select(2:4)|>  
  correlation::correlation(method = "pearson")|> 
  plot()
# Opcao3
PerformanceAnalytics::chart.Correlation(salarios[2:8], histogram = T)

# Modelo 1
modelo1 <- lm(formula = salario ~ rh1 + econometria1,
              data = salarios)
summary(modelo1)

# Call:
#   lm(formula = salario ~ rh1 + econometria1, data = salarios)
# 
# Residuals:
#   Min      1Q  Median      3Q     Max 
# -149.53  -89.98  -63.85  118.46  261.84 
# 
# Coefficients: (1 not defined because of singularities)
# Estimate Std. Error t value Pr(>|t|)    
# (Intercept)   1213.80     109.75  11.060 5.53e-08 ***
#   rh1            127.87      16.26   7.865 2.69e-06 ***
#   econometria1       NA         NA      NA       NA    
# ---
#   Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1
# 
# Residual standard error: 135.2 on 13 degrees of freedom
# Multiple R-squared:  0.8263,	Adjusted R-squared:  0.813 
# F-statistic: 61.85 on 1 and 13 DF,  p-value: 2.695e-06

# Conclus√£o: O beta da econometria1 (perfeitamente correlacionada com a 
# rh1) vem como NA. Isso acontece porque elas s√£o perfeitamente correlacionadas. 
# Nas vari√°veis quase perfeitamente correlacionada ocorre a mesma coisa, mas 
# resguardando a quantidade de correla√ß√£o, como nem sempre √© perfeitamente correlacionado
# vem um valor bem pequeno de explcia√ß√£o, n√£o vai vir NA (zerado)


# se Utilizar o procedimento stepwise obter√≠amos o mesmo modelo que consideramos
# ideal acima, o que conta apenas com uma das var. correlacionadas. Pois, o 
# modelo step j√° toma esse cuidado de eliminar var. altamente correlacionadas
modelo1_step <- step(lm(formula = salario ~ rh1 + econometria1, data = salarios),
                     k = (qchisq(p = 0.05, df = 1, lower.tail = F)))
summary(modelo1_step)


## Exemplo 2
## CORRELA√á√ÉO BAIXA:
cor(salarios$rh3, salarios$econometria3)

salarios %>% select(2,7,8) %>% 
  correlation(method = "pearson") %>%
  plot()

modelo3 <- lm(formula = salario ~ rh3 + econometria3,
              data = salarios)
summary(modelo3)


# Diagn√≥stico -------------------------------------------------------------
# A tolerancia = 1 - R¬≤ da variavel preditora (de uma variavel explicativa contra
# a outra) para avaliar a magnitude. Tolerancia quanto mais perto de 1, significa uma 
# multicolinearidade baixa. A tolerancia pr√≥ximo de zero significa alta colinearidade
# A toler√Çnica √© zero quando a correla√ß√£o for perfeita

# VIF: Quando VIF pr√≥ximo a 1 significa baixa colinearidade. Quando VIF tende
# ao infinito, temos multicolinearidade (ex. modelo1)
# VIF = 1/Tolerance


# Diagn√≥stico de multicolinearidade (Variance Inflation Factor e Tolerance)
olsrr::ols_vif_tol(modelo3) # sem colinearidade
olsrr::ols_vif_tol(modelo1) # alta colinearidade (correla√ß√£o perfeita)


# Modelo Auxiliar: Uma vari√°vel preditora contra a outra
modelo_aux3 <- lm(rh3 ~ econometria3, data= salarios)
summary(modelo_aux3)

# Podemos calcular manualmente a Tolerancia e o VIF
# Tolerancia
tolerance = 1 - 0.07027 # (valor do R-squared)
tolerance
# 0.92973 - como a Tolerancia deu pr√≥ximo a 1, deu indicio de baixa colinearidade
# VIF
VIF <- 1/tolerance
VIF
# 1.075581 - Como VIF proximo a 1, deu indicio de baixa colinearidade

# Op√ß√£o 2 - rodar lm com as vari√°veis q estamos testando a colinearidade
olsrr::ols_vif_tol(modelo_aux3)


# Como Detectar? -----------------------------------

# 1. Teste-t n√£o significativo e Teste F significativo (p<0.05 no global)
#     As vezes o p √© menor do que 0.05 no teste global (teste F)
#     Mas os valores de beta n√£o d√£o significativo (teste t)


# Call:
#   lm(formula = salario ~ rh2 + econometria2, data = salarios)
# 
# Residuals:
#   Min      1Q  Median      3Q     Max 
# -153.00  -97.61  -58.55  107.97  261.88 
# 
# Coefficients:
#   Estimate Std. Error t value Pr(>|t|)    
# (Intercept)    1241.9      130.2   9.540 5.94e-07 ***
#   rh2             194.1      152.1   1.276    0.226    
# econometria2   -139.5      318.3  -0.438    0.669    
# ---
#   Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1
# 
# Residual standard error: 139.6 on 12 degrees of freedom
# Multiple R-squared:  0.8291,	Adjusted R-squared:  0.8006 
# F-statistic:  29.1 on 2 and 12 DF,  p-value: 2.495e-05


# Isso pode acontecer quando temos vari√°veis muito correlacionadas entre si
# no modelo.

# Vamos olhar:
## CORRELA√á√ÉO MUITO ALTA, POR√âM N√ÉO PERFEITA:
cor(salarios$rh2, salarios$econometria2)
salarios %>% select(2,5,6) %>% 
  correlation::correlation(method = "pearson") %>%
  plot()
# MOdelo
modelo2 <- lm(formula = salario ~ rh2 + econometria2,
              data = salarios)
summary(modelo2)
ols_vif_tol(modelo2)

# Conclus√£o: Olha o valor do VIF (82.06), significa que temos uma correla√ß√£o
# alta entre essas vari√°veis. Elas explicam praticamente a mesma coisa que a 
# outra.

# Se refizer o modelo s√≥ com uma vari√°vel melhora: o p continua significativo
# o beta passa a ser significativo e o R¬≤ se mant√©m com 82% de explica√ß√£o
modelo2 <- lm(formula = salario ~ rh2,
              data = salarios)
summary(modelo2)

# 2. Sinais inesperados dos coeficientes


# Fontes --------------------------------------------
# Fontes de Multicolinearidade
#> 1 - Existencia de vari√°veis que apresentam a mesma tend√™ncia durante alguns
#>     per√≠odos, em decorr√™ncia da sele√ß√£o de uma amostra que inclua apenas
#>     observa√ß√µes referentes a estes per√≠odos
#> 2 - Utiliza√ß√£o de amostras com reduzido n√∫mero de observa√ß√µes
#> 3 - Utiliza√ß√£o de valores defasados em algumas das vari√°veis explicativas
#>     como "novas" explicativas



# x -----------------------------------------------------------------------
# x -----------------------------------------------------------------------

# Pressuposto: Heterocedasticidade ----------------------------------------
# Heterocedasticidade: significa que existe correla√ß√£o entre o valor de X
# e o termo de erro. Neste caso, quanto maior o valor de X, maior o erro
# se a correla√ß√£o entre o termo de erro e o valor de X for significativamente
# diferente de zero, temos heterocedasticidade ocorrendo. Varia√ß√£o dos termos
# de erro n√£o s√£o constantes ao longo de X.

# Isso mostra a omiss√£o de vari√°veis X importantes para explicar Y. Alguma
# vari√°vel importante pode n√£o ter entrado no modelo. 


# Ind√≠cios ----------------------------------------------------------------
# - os erros n√£o est√£o distribu√≠dos de forma aleat√≥ria. Formam um cone.
# Indicando que quanto maior o valor de X, maior o erro. Isso pode afetar a 
# predi√ß√£o na parte mais aberta do cone
# - forma inadequada do modelo (o linear n√£o seria o adequado).



# Dados
# Fatores que podem interferir no aprendizado dos estudantes
load(file = "raw_datas_exemplos/saeb_rend.RData")

glimpse(saeb_rend)
saeb_rend$codigo <- as.character(saeb_rend$codigo)

# Analise explorat√≥ria
summary(saeb_rend)

# Tabela de frequ√™ncias absolutas das vari√°veis 'uf' e rede'
table(saeb_rend$uf)
table(saeb_rend$rede)


# Exemplo de Heterocedasticidade - aumento do erro, com o aumento de X
# Plotando saeb em fun√ß√£o de rendimento, com linear fit
ggplotly(
  ggplot(saeb_rend, aes(x = rendimento, y = saeb)) +
    geom_point(size = 1, color = "#FDE725FF") +
    geom_smooth(method = "lm", formula = y ~ x,
                color = "grey40", se = F) +
    xlab("rendimento") +
    ylab("saeb") +
    theme_classic()
)

# Plotando saeb em fun√ß√£o de rendimento, com destaque para rede escolar 
ggplotly(
  ggplot(saeb_rend, aes(x = rendimento, y = saeb, color = rede, shape = rede)) +
    geom_point(size = 1) +
    xlab("rendimento") +
    ylab("saeb") +
    scale_colour_viridis_d() +
    theme_classic()
)

# Plotando saeb em fun√ß√£o de rendimento, com destaque para rede escolar e linear fits
ggplotly(
  ggplot(saeb_rend, aes(x = rendimento, y = saeb, color = rede, shape = rede)) +
    geom_point(size = 1) +
    geom_smooth(method = "lm", formula = y ~ x, se = F) +
    xlab("rendimento") +
    ylab("saeb") +
    scale_colour_viridis_d() +
    theme_classic()
)


# Diagn√≥stico -------------------------------------------------------------

#Estima√ß√£o do modelo
modelosaeb <- lm(formula = saeb ~ rendimento,
                 data = saeb_rend)

summary(modelosaeb)

# Call:
#   lm(formula = saeb ~ rendimento, data = saeb_rend)
# 
# Residuals:
#   Min      1Q  Median      3Q     Max 
# -3.0566 -0.4593  0.0189  0.4762  3.3058 
# 
# Coefficients:
#   Estimate Std. Error t value Pr(>|t|)    
# (Intercept)  3.24246    0.03941   82.28   <2e-16 ***
#   rendimento   2.06646    0.04481   46.11   <2e-16 ***
#   ---
#   Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1
# 
# Residual standard error: 0.7241 on 25528 degrees of freedom
# (18077 observations deleted due to missingness)
# Multiple R-squared:  0.07689,	Adjusted R-squared:  0.07685 
# F-statistic:  2126 on 1 and 25528 DF,  p-value: < 2.2e-16


# Temos o p significativo para o teste F e para o teste t (beta).
# Mas o R¬≤ foi muito pequeno.


# Teste Breusch-Pagan  ------------------------------------------------------------------
# Usado para diagn√≥stico de heterocedasticida
#     H0 do teste: aus√™ncia de heterocedasticidade.
#     H1 do teste: heterocedasticidade, ou seja, correla√ß√£o entre res√≠duos e uma ou mais
#                  var. explicativas
olsrr::ols_test_breusch_pagan(modelosaeb)

# Conclus√£o: Se Prob > Chi2 for <0.05, existe heterocedasticidade. Que pode ter
# ocorrido pela omiss√£o de vari√°vel(is) explicativa(s) relevante(s)


#     #     #     #       #      #      #     #       #       #
# Abrindo a caixa preta do teste

# Extrair os valores preditos
saeb_rend$yhat <- modelosaeb$fitted.values # N√£o funciona pq tem NAs
saeb_rend$yhat <- predict(object = modelosaeb, newdata = saeb_rend) #fazer assim para enganar o r

#extrair os res√≠duos
saeb_rend$resid <- modelosaeb$residuals # N√£o funciona pq tem NAs
saeb_rend$resid <- saeb_rend$saeb - saeb_rend$yhat  # observado - esperado -> fazer assim para enganar o r

# formula do teste:
saeb_rend$up <- ((saeb_rend$resid)^2)/((sum(saeb_rend$resid^2, na.rm =TRUE))/(25530))
modelo_aux <- lm(up ~ yhat, data = saeb_rend)
# pegar a soma dos quadrados da regressao e dividir por 2
anova(modelo_aux)
pchisq(33.441/2,df=1,lower.tail = F)

saeb_rend$yhat <- NULL
saeb_rend$resid <- NULL
saeb_rend$up <- NULL

#     #     #     #       #      #      #     #       #       #





#     #     #     #       #      #      #     #       #       #

# Heterocedasticidade para Vari√°veis Dummies -------------------------------------
saeb_rend_dummies_uf <- dummy_columns(.data = saeb_rend,
                                      select_columns = "uf",    # selecionar coluna uf para virar dummie
                                      remove_selected_columns = T,    # remover coluna original sem ser dummie
                                      remove_most_frequent_dummy = T) # categoria mais frequente como referencia


# Colocando a primeira vari√°vel dummie que aparece como referencia
saeb_rend_dummies_uf <- dummy_columns(.data = saeb_rend,
                                      select_columns = "uf",    
                                      remove_selected_columns = T,    
                                      remove_first_dummy = T) # Primeira categoria como referencia


# Escolhendo manualmente a categoria de referencia
saeb_rend_dummies_uf <- dummy_columns(.data = saeb_rend,
                                      select_columns = "uf",    
                                      remove_selected_columns = T) 
saeb_rend_dummies_uf <- saeb_rend_dummies_uf[,-11] # a 11 coluna sera referencia




# Diagn√≥stico -------------------------------------------------------------
modelosaeb_dummies_uf <- lm(formula = saeb ~ . -municipio -codigo -escola -rede,
                            data = saeb_rend_dummies_uf)

summary(modelosaeb_dummies_uf)


# Teste de Breusch-Pagan para diagn√≥stico de heterocedasticidade
ols_test_breusch_pagan(modelosaeb_dummies_uf)

# Resultado: 
# DF            =    1 
# Chi2          =    1.075624 
# Prob > Chi2   =    0.2996785 

# Conclus√£o: Como H0 do teste significa aus√™ncia de heterocedasticidade, 
# n√£o existe heterocedasticidade nesses dados


# Plotando saeb em fun√ß√£o de rendimento, com destaque para UFs e linear fits
ggplotly(
  ggplot(saeb_rend, aes(x = rendimento, y = saeb, color = uf, shape = uf)) +
    geom_point(size = 1) +
    geom_smooth(method = "lm", formula = y ~ x, se = F) +
    xlab("rendimento") +
    ylab("saeb") +
    scale_colour_viridis_d() +
    theme_classic()
)

ggplot(saeb_rend, aes(x = rendimento, y = saeb, color = uf, shape = uf)) +
  geom_point(size = 1) +
  geom_smooth(method = "lm", formula = y ~ x, se = F) +
  xlab("rendimento") +
  ylab("saeb") +
  scale_colour_viridis_d() +
  theme_classic()

#     #     #     #       #      #      #     #       #       #




# x -----------------------------------------------------------------------
# x -----------------------------------------------------------------------
# Regress√£o N√£o-Linear Multipla com Dummies -------------------------------

# Dados
load(file = "raw_datas_exemplos/planosaude.RData")

# Exploratorio
glimpse(planosaude)
summary(planosaude)
levels(factor(planosaude$plano))

# Acertar tipos de variaveis
planosaude$id <- as.character(planosaude$id) 
planosaude$plano <- as.factor(planosaude$plano)


# Tabela de frequ√™ncias absolutas da vari√°vel 'plano'
table(planosaude$plano)


# Correla√ß√µes - somente vari√°veis quantitativas
chart.Correlation((planosaude[2:5]), histogram = TRUE)


# Dummies -----------------------------------------------------------------
# Transformar a variavel qualitativa em dummie. Salvar nova base de dados
# para n√£o interferir na base de dados original
planosaude_dummies <- dummy_columns(.data = planosaude,
                                    select_columns = "plano",
                                    remove_selected_columns = T,
                                    remove_most_frequent_dummy = T)
# Visualizando a base de dados dummizada
planosaude_dummies %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped", 
                full_width = F, 
                font_size = 23)


# Estimar Modelo Linear ---------------------------------------------------

# Modelagem com todas as vari√°veis
modelo_planosaude <- lm(despmed ~ . - id, planosaude_dummies)

# Par√¢metros do modelo_planosaude
summary(modelo_planosaude)


# Stepwise ----------------------------------------------------------------
# antes de interpretar, vamos tirar as vari√°veis que n√£o passaram
step_planosaude <- step(modelo_planosaude, k = 3.841459)
# ou
step_planosaude <- step(modelo_planosaude, k = qchisq(p = 0.05, df = 1, lower.tail = F))

summary(step_planosaude)



# Teste dos Pressupostos --------------------------------------------------



# Testar: ADER√äNCIA DOS RES√çDUOS √Ä NORMALIDADE ----------------------------
# Lembrando que se tiver missing values, a extra√ß√£o do res√≠duo n√£o vai rodar e teriamos
# que criar um predict com o modelo para ele aceitar o missing value e retornar os res√≠duos
# object = modelo de regressao
# newdata= dados usados para gerar o modelo
# planosaude_dummies$yhat <- predict( object = step_planosaude (=modelo), newdata= planosaude_dummies)
# planosaude_dummies$resid <- planosaude_dummies$despmed - planosaude_dummies$yhat   (=obs - esp)

# Teste de Shapiro-Francia
# p<0.05 = n√£o existe normalidade
nortest::sf.test(step_planosaude$residuals)


# Plotando os res√≠duos do modelo step_planosaude 
planosaude %>%
  mutate(residuos = step_planosaude$residuals) %>%
  ggplot(aes(x = residuos)) +
  geom_histogram(color = "white", 
                 fill = "#55C667FF", 
                 bins = 15,
                 alpha = 0.6) +
  labs(x = "Res√≠duos",
       y = "Frequ√™ncias") + 
  theme_bw()

# Acrescentando uma curva normal te√≥rica para compara√ß√£o entre as distribui√ß√µes
planosaude %>%
  mutate(residuos = step_planosaude$residuals) %>%
  ggplot(aes(x = residuos)) +
  geom_histogram(aes(y = ..density..), 
                 color = "white", 
                 fill = "#55C667FF", 
                 bins = 15,
                 alpha = 0.6) +
  stat_function(fun = dnorm, 
                args = list(mean = mean(step_planosaude$residuals),
                            sd = sd(step_planosaude$residuals)),
                size = 2, color = "grey30") +
  scale_color_manual(values = "grey50") +
  labs(x = "Res√≠duos",
       y = "Frequ√™ncia") +
  theme_bw()

# Conclus√£o: este histograma mostra que n√£o houve aderencia dos valores de 
# res√≠duo a normalidade. A curva normal te√≥rica √© signif. diferente das barras que 
# representam os res√≠duos.


# Kernel density estimation (KDE) - forma n√£o-param√©trica para estimar a
# fun√ß√£o densidade de probabilidade de uma vari√°vel aleat√≥ria
planosaude_dummies %>%
  ggplot() +
  geom_density(aes(x = step_planosaude$residuals), fill = "#55C667FF") +
  labs(x = "Res√≠duos do Modelo Stepwise",
       y = "Densidade") +
  theme_bw()


# Testar: HETEROCEDASTICIDADE ---------------------------------------------

# Teste de Breusch-Pagan para diagn√≥stico de heterocedasticidade
olsrr::ols_test_breusch_pagan(step_planosaude)

# Conclus√£o: p<0.05, n√£o passa. Os dados s√£o heterocedasticos, ou seja, pode
# ter ocorrido omiss√£o de alguma vari√°vel explicativa relevante e/ou forma
# inadequada do modelo (o linear n√£o seria o adequado).


# Adicionando fitted values e res√≠duos do modelo 'step_planosaude'
# no dataset 'planosaude_dummies'
planosaude_dummies$fitted_step <- step_planosaude$fitted.values
planosaude_dummies$residuos_step <- step_planosaude$residuals

# Gr√°fico que relaciona res√≠duos e fitted values do modelo 'step_planosaude'
planosaude_dummies %>%
  ggplot() +
  geom_point(aes(x = fitted_step, y = residuos_step),
             color = "#55C667FF", size = 3) +
  labs(x = "Fitted Values do Modelo Stepwise",
       y = "Res√≠duos do Modelo Stepwise") +
  theme_bw()


# Transforma√ß√£o de BoxCox -------------------------------------------------

#Para calcular o lambda de Box-Cox
lambda_BC <- powerTransform(planosaude$despmed)
lambda_BC

# Inserindo o lambda de Box-Cox na nova base de dados para a estima√ß√£o de um
# novo modelo
planosaude_dummies$bcdespmed <- (((planosaude$despmed ^ lambda_BC$lambda) - 1) / 
                                   lambda_BC$lambda)

# Visualizando a nova vari√°vel na base de dados
planosaude_dummies %>%
  select(id, despmed, bcdespmed, everything()) %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped", 
                full_width = F, 
                font_size = 14)

# Estimando um novo modelo m√∫ltiplo com dummies
modelo_bc_planosaude <- lm(formula = bcdespmed ~ . -id -despmed -fitted_step
                           -residuos_step, 
                           data = planosaude_dummies)

# Par√¢metros do modelo
summary(modelo_bc_planosaude)

# Aplicando o procedimento Stepwise
step_bc_planosaude <- step(modelo_bc_planosaude, k = qchisq(p = 0.05, df = 1, lower.tail = F))
summary(step_bc_planosaude)

# Verificando a normalidade dos res√≠duos do modelo step_bc_planosaude
# Teste de Shapiro-Francia
nortest::sf.test(step_bc_planosaude$residuals) # normal

# Plotando os novos res√≠duos do modelo step_bc_planosaude com curva normal te√≥rica
planosaude_dummies %>%
  mutate(residuos = step_bc_planosaude$residuals) %>%
  ggplot(aes(x = residuos)) +
  geom_histogram(aes(y = ..density..), 
                 color = "white", 
                 fill = "#440154FF", 
                 bins = 15,
                 alpha = 0.6) +
  stat_function(fun = dnorm, 
                args = list(mean = mean(step_bc_planosaude$residuals),
                            sd = sd(step_bc_planosaude$residuals)),
                size = 2, color = "grey30") +
  scale_color_manual(values = "grey50") +
  labs(x = "Res√≠duos",
       y = "Frequ√™ncia") +
  theme_bw()

# Kernel density estimation (KDE)
planosaude_dummies %>%
  ggplot() +
  geom_density(aes(x = step_bc_planosaude$residuals), fill = "#440154FF") +
  labs(x = "Res√≠duos do Modelo Stepwise com Transforma√ß√£o de Box-Cox",
       y = "Densidade") +
  theme_bw()

# Diagn√≥stico de Heterocedasticidade para o Modelo Stepwise com Box-Cox
ols_test_breusch_pagan(step_bc_planosaude) # n√£o heteroced√°stico

# Adicionando fitted values e res√≠duos do modelo 'step_bc_planosaude'
# no dataset 'planosaude_dummies'
planosaude_dummies$fitted_step_novo <- step_bc_planosaude$fitted.values
planosaude_dummies$residuos_step_novo <- step_bc_planosaude$residuals

# Gr√°fico que relaciona res√≠duos e fitted values do modelo 'step_bc_planosaude'
planosaude_dummies %>%
  ggplot() +
  geom_point(aes(x = fitted_step_novo, y = residuos_step_novo),
             color = "#440154FF", size = 3) +
  labs(x = "Fitted Values do Modelo Stepwise com Transforma√ß√£o de Box-Cox",
       y = "Res√≠duos do Modelo Stepwise com Transforma√ß√£o de Box-Cox") +
  theme_bw()


